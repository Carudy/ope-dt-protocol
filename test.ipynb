{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import nacl.encoding\n",
    "import nacl.hash\n",
    "\n",
    "from utils import *\n",
    "from ore import *\n",
    "from bplustree import *\n",
    "from node import *\n",
    "from read_data import *\n",
    "from dtree import *\n",
    "from mpc import sim_mpc_n\n",
    "from he import sim_he_n\n",
    "from rf import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose 50/500 features.\n",
      "Start training rf..\n",
      "Training rf 1/20\n",
      "Training rf 2/20\n",
      "Training rf 3/20\n",
      "Training rf 4/20\n",
      "Training rf 5/20\n",
      "Training rf 6/20\n",
      "Training rf 7/20\n",
      "Training rf 8/20\n",
      "Training rf 9/20\n",
      "Training rf 10/20\n",
      "Training rf 11/20\n",
      "Training rf 12/20\n",
      "Training rf 13/20\n",
      "Training rf 14/20\n",
      "Training rf 15/20\n",
      "Training rf 16/20\n",
      "Training rf 17/20\n",
      "Training rf 18/20\n",
      "Training rf 19/20\n",
      "Training rf 20/20\n",
      "End training rf.\n",
      "Saving rf.\n",
      "Saving rf done.\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForest(n_tree=20, max_f=0.1)\n",
    "dataset = read_libsvm(name='madelon')\n",
    "rf.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5065"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(dataset, [x[-1] for x in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = CartTree()\n",
    "dt.fit(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.score(dataset, [x[-1] for x in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ore_encoding_ore():\n",
    "    ore = ORE(key='123')\n",
    "    A = sorted([random.randint(-434531, 43454) for _ in range(100)])\n",
    "    B = [scale_val(x) for x in A]\n",
    "    C = [ore.encode(x) for x in B]\n",
    "    co = Coordinator()\n",
    "    co.receive_keys(C[:50], C[50:])\n",
    "    co.mp_map.update(co.do_map)\n",
    "    d = co.mp_map.copy()\n",
    "\n",
    "    for i in range(len(C)):\n",
    "        for j in range(i):\n",
    "            x, y = OREncoding(d[C[j].x]), OREncoding(d[C[i].x])\n",
    "            a = ore.compare(C[j], C[i])\n",
    "            b = ore.compare(x, y)\n",
    "            if a != -1 or a != b:\n",
    "                print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate():\n",
    "    co = Coordinator()\n",
    "    do = DataOwner()\n",
    "    mp = ModelProvider()\n",
    "    mp.train_model()\n",
    "\n",
    "    key_0 = str(random.randint(0, 1000))\n",
    "    do.ore.key = key_0\n",
    "    mp.ore.key = key_0\n",
    "    do_encs = do.get_encodings()\n",
    "    mp_encs = mp.get_encodings()\n",
    "    co.receive_keys(mp_arr=mp_encs, do_arr=do_encs)\n",
    "\n",
    "    mp.receive_map(co.mp_map)\n",
    "    do.receive_map(co.do_map)\n",
    "\n",
    "    enc_dataset = []\n",
    "    for sample in do.dataset:\n",
    "        _s = sample[:]\n",
    "        for i in range(len(_s)-1):\n",
    "            _v = do.ore.encode(scale_val(_s[i])).x\n",
    "            _s[i] = OREncoding(do.ore_map[_v])\n",
    "        enc_dataset.append(_s)\n",
    "\n",
    "    ys = [x[-1] for x in enc_dataset]\n",
    "    pred = mp.model.predict(enc_dataset)\n",
    "    print(f'ACC: {accuracy_score(pred, ys) * 100:.2f}%')\n",
    "\n",
    "# simulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MP model score: 87.28%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47eb553e425246adbdd7121edeb5a0b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1647 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2dc0692f81a4754b6540f32a2f5f51c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1654 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data inserted into tree.\n",
      "All data mapped to encoding.\n",
      "0.020ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "co = Coordinator()\n",
    "do = DataOwner()\n",
    "mp = ModelProvider()\n",
    "mp.train_model()\n",
    "\n",
    "key_0 = str(random.randint(0, 1000))\n",
    "do.ore.key = key_0\n",
    "mp.ore.key = key_0\n",
    "do_encs = do.get_encodings()\n",
    "mp_encs = mp.get_encodings()\n",
    "\n",
    "st = time.time()\n",
    "tt = co.receive_keys(mp_arr=mp_encs, do_arr=do_encs)\n",
    "tp = (time.time() - st) * 1000\n",
    "print(f'{tp/len(mp.dataset):.3f}ms')\n",
    "\n",
    "# mp.receive_map(co.mp_map)\n",
    "# do.receive_map(co.do_map)\n",
    "# do.dataset = read_rna()\n",
    "# enc_dataset = []\n",
    "# _ys = []\n",
    "# _st = time.time()\n",
    "# _i = 0\n",
    "# for sample in do.dataset:\n",
    "#     _s = sample[:]\n",
    "#     _i += 1\n",
    "#     for i in range(len(_s)-1):\n",
    "#         _v = do.ore.encode(scale_val(_s[i])).x\n",
    "#         _s[i] = OREncoding(do.ore_map[_v])\n",
    "#     enc_dataset.append(_s)\n",
    "#     if _i in _xs:\n",
    "#         _ys.append((time.time()-_st)*1000)\n",
    "#     if _i > _xs[-1]:\n",
    "#         break\n",
    "# ys = [x[-1] for x in enc_dataset]\n",
    "# pred = mp.model.predict(enc_dataset)\n",
    "# str(_ys)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afaa4d4e18bd142e5143da94ae0022aa03911ed6b2491709ef134715416f752a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
